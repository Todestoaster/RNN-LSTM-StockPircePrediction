{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f58d2aa4-916f-40e4-acdd-93b10496e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import save_model, load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import joblib\n",
    "\n",
    "# Erstelle den Ordner zum Speichern der Modelle, falls nicht bereits vorhanden\n",
    "os.makedirs('./models', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1cd89d2-67b5-44d3-b7fa-1f88919aaf3b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2257,
     "status": "ok",
     "timestamp": 1728643005227,
     "user": {
      "displayName": "JoVideo27",
      "userId": "02860430691370071959"
     },
     "user_tz": -120
    },
    "id": "b1cd89d2-67b5-44d3-b7fa-1f88919aaf3b",
    "outputId": "28b635c8-8a42-438a-de7f-8100af662fec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low     Close  Adj Close     Volume\n",
      "Date                                                                    \n",
      "2000-01-03  0.936384  1.004464  0.907924  0.999442   0.844004  535796800\n",
      "2000-01-04  0.966518  0.987723  0.903460  0.915179   0.772846  512377600\n",
      "2000-01-05  0.926339  0.987165  0.919643  0.928571   0.784155  778321600\n",
      "2000-01-06  0.947545  0.955357  0.848214  0.848214   0.716296  767972800\n",
      "2000-01-07  0.861607  0.901786  0.852679  0.888393   0.750226  460734400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Lade die historischen Daten einer Aktie (z.B. Apple)\n",
    "symbol = \"AAPL\"  # Apple-Aktien\n",
    "start_date = \"2000-01-01\"  # Startdatum für die Daten\n",
    "end_date = \"2024-10-10\"    # Enddatum für die Daten\n",
    "\n",
    "# CSV-Datei für die Ergebnisse\n",
    "csv_filename = f'./results/hyperparameter_search_results_{start_date}_{end_date}.csv'\n",
    "os.makedirs('./results', exist_ok=True)\n",
    "\n",
    "# Daten herunterladen von Yahoo Finance\n",
    "df = yf.download(symbol, start=start_date, end=end_date)\n",
    "\n",
    "# Überprüfen der Daten\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "637e1447-55ea-4817-b161-af305a5ec846",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 938,
     "status": "ok",
     "timestamp": 1728643006163,
     "user": {
      "displayName": "JoVideo27",
      "userId": "02860430691370071959"
     },
     "user_tz": -120
    },
    "id": "637e1447-55ea-4817-b161-af305a5ec846",
    "outputId": "96c9445c-914f-497c-da63-907bb0321919"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./scaler/target_scaler.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Daten aus den relevanten Spalten entnehmen\n",
    "features = df[['Open', 'High', 'Low', 'Adj Close', 'Volume']]\n",
    "target = df['Close']\n",
    "\n",
    "# MinMaxScaler initialisieren und die Features skalieren\n",
    "feature_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "target_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaled_features = feature_scaler.fit_transform(features)\n",
    "scaled_target = target_scaler.fit_transform(target.values.reshape(-1, 1))\n",
    "\n",
    "joblib.dump(feature_scaler, './scaler/feature_scaler.pkl')\n",
    "joblib.dump(target_scaler, './scaler/target_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df63270f-748e-4faa-af86-6aa47680b434",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1728643009201,
     "user": {
      "displayName": "JoVideo27",
      "userId": "02860430691370071959"
     },
     "user_tz": -120
    },
    "id": "df63270f-748e-4faa-af86-6aa47680b434"
   },
   "outputs": [],
   "source": [
    "val_size= 0.2\n",
    "# Definiere die möglichen Werte für die Hyperparameter\n",
    "hyperparameters = {\n",
    "    'windowsize': [1, 2, 5, 10, 15, 20, 30, 60],\n",
    "    'batchsize': [1, 5, 14, 30, 64, 128, 256, 512],\n",
    "    'epochs': [30],\n",
    "    'units': [1, 2, 5, 6, 8, 12, 16, 32, 64, 128],\n",
    "    'lstm_layers': [1, 2, 3],\n",
    "    'future_steps': [2, 3, 4, 5, 10, 30, 60]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0215dda-2607-4224-a3ef-6e5f29d61da4",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1728643009201,
     "user": {
      "displayName": "JoVideo27",
      "userId": "02860430691370071959"
     },
     "user_tz": -120
    },
    "id": "d0215dda-2607-4224-a3ef-6e5f29d61da4"
   },
   "outputs": [],
   "source": [
    "# Prüfe, ob das Modell bereits existiert\n",
    "def model_exists(window_size, future_steps, batch_size, epochs, units, lstm_layers):\n",
    "    if os.path.exists(csv_filename):\n",
    "        with open(csv_filename, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            for row in reader:\n",
    "                if row[1:6] == [str(window_size), str(future_steps), str(batch_size), str(epochs), str(units), str(lstm_layers)]:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "# Schreibe oder appende die Ergebnisse in die CSV\n",
    "def write_to_csv(model_name, window_size, future_steps, batch_size, epochs, units, lstm_layers, mse, mae, r2):\n",
    "    file_exists = os.path.isfile(csv_filename)\n",
    "    with open(csv_filename, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            # Header hinzufügen, wenn die Datei neu erstellt wird\n",
    "            writer.writerow(['Model Name', 'Window Size', 'Future Steps', 'Batch Size', 'Epochs', 'Units', 'LSTM Layers', 'MSE', 'MAE', 'R2'])\n",
    "        writer.writerow([model_name, window_size, future_steps, batch_size, epochs, units, lstm_layers, mse, mae, r2])\n",
    "\n",
    "def create_sliding_window(data, target, window_size, future_steps):\n",
    "    \"\"\"\n",
    "    Erstellt Sliding-Window-Daten aus den Merkmalen und Zielwerten.\n",
    "    :param data: Skalierte Eingabedaten (Features)\n",
    "    :param target: Skalierte Zielwerte (Target)\n",
    "    :param window_size: Anzahl der vorhergehenden Tage (Fenstergröße)\n",
    "    :param future_steps: Anzahl der Tage in die Zukunft, die vorhergesagt werden\n",
    "    :return: X, y - Arrays mit den Feature-Sequenzen und den Zielwerten\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size - future_steps):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(target[i + window_size:i + window_size + future_steps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# Zufällige Suche über die Hyperparameter\n",
    "def random_search(n_iter=10):\n",
    "    results = []\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        # Zufällige Auswahl von Hyperparametern\n",
    "        window_size = np.random.choice(hyperparameters['windowsize'])\n",
    "        batch_size = np.random.choice(hyperparameters['batchsize'])\n",
    "        epochs = np.random.choice(hyperparameters['epochs'])\n",
    "        units = int(np.random.choice(hyperparameters['units']))\n",
    "        lstm_layers = np.random.choice(hyperparameters['lstm_layers'])\n",
    "        future_steps = np.random.choice(hyperparameters['future_steps'])\n",
    "\n",
    "        print(f\"Iteration: {_}, window_size={window_size}, future_steps={future_steps}, batch_size={batch_size}, epochs={epochs}, units={units}, lstm_layers={lstm_layers}\")\n",
    "\n",
    "        # Prüfe, ob das Modell mit diesen Parametern bereits existiert\n",
    "        if model_exists(window_size, future_steps, batch_size, epochs, units, lstm_layers):\n",
    "            print(f\"Modell mit den Parametern (ws={window_size}, future_steps={future_steps}, bs={batch_size}, ep={epochs}, units={units}, layers={lstm_layers}) existiert bereits. Überspringe...\")\n",
    "            continue\n",
    "\n",
    "        # Daten vorbereiten mit aktuellem window_size und future_steps\n",
    "        X, y = create_sliding_window(scaled_features, scaled_target, window_size=window_size, future_steps=future_steps)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=val_size, random_state=42)\n",
    "\n",
    "        # Modell erstellen\n",
    "        model = Sequential()\n",
    "\n",
    "        # Ersten LSTM Layer hinzufügen\n",
    "        model.add(LSTM(units=units, return_sequences=True if lstm_layers > 1 else False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        # Weitere LSTM Layer falls vorhanden\n",
    "        for layer in range(1, lstm_layers):\n",
    "            model.add(LSTM(units=units, return_sequences=False if layer == lstm_layers - 1 else True))\n",
    "            model.add(Dropout(0.2))\n",
    "\n",
    "        # Dense-Schicht hinzufügen\n",
    "        model.add(Dense(units=future_steps))  # Vorhersage von mehreren Schritten\n",
    "\n",
    "        # Modell kompilieren\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        earlystop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        \n",
    "        # Modell trainieren\n",
    "        history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), verbose=1, callbacks=[earlystop])\n",
    "\n",
    "        # Vorhersagen auf den Validierungsdaten\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Den Skalierungsfaktor rückgängig machen, um die echten Werte wiederherzustellen\n",
    "        y_val_reshaped = y_val.reshape(-1, future_steps)\n",
    "        y_pred_reshaped = y_pred.reshape(-1, future_steps)\n",
    "\n",
    "        # Den Skalierungsfaktor rückgängig machen, um die echten Werte wiederherzustellen\n",
    "        y_val_true = target_scaler.inverse_transform(y_val_reshaped)\n",
    "        y_pred_rescaled = target_scaler.inverse_transform(y_pred_reshaped)\n",
    "\n",
    "        # Berechne die Metriken (z.B. nur für den letzten vorhergesagten Tag)\n",
    "        mse = mean_squared_error(y_val_true[:, -1], y_pred_rescaled[:, -1])\n",
    "        mae = mean_absolute_error(y_val_true[:, -1], y_pred_rescaled[:, -1])\n",
    "        r2 = r2_score(y_val_true[:, -1], y_pred_rescaled[:, -1])\n",
    "\n",
    "        # Ergebnisse ausgeben\n",
    "        print(f\"Validation MSE: {mse}, MAE: {mae}, R2: {r2}\")\n",
    "\n",
    "        # Modellname basierend auf einem Zeitstempel\n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        model_name = f\"model_{timestamp}_ws{window_size}_fs{future_steps}_bs{batch_size}_epochs{epochs}_units{units}_layers{lstm_layers}.keras\"\n",
    "        save_model(model, f'./models/{model_name}')\n",
    "\n",
    "        # Ergebnis in die CSV-Datei schreiben\n",
    "        write_to_csv(model_name, window_size, future_steps, batch_size, epochs, units, lstm_layers, mse, mae, r2)\n",
    "\n",
    "        # Ergebnis in die Resultsliste einfügen\n",
    "        results.append((window_size, future_steps, batch_size, epochs, units, lstm_layers, mse, mae, r2, model_name))\n",
    "\n",
    "    # Ergebnisse sortieren nach dem besten MSE\n",
    "    results = sorted(results, key=lambda x: x[5])  # Sortiere nach MSE\n",
    "    best_params = results[0]\n",
    "\n",
    "    print(\"\\nBeste Hyperparameter-Kombination:\")\n",
    "    print(f\"window_size={best_params[0]}, future_steps={best_params[1]}, batch_size={best_params[2]}, epochs={best_params[3]}, units={best_params[4]}, lstm_layers={best_params[5]}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7371f15f-1500-4596-b778-8342e5dafa9e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3396286,
     "status": "ok",
     "timestamp": 1728646405483,
     "user": {
      "displayName": "JoVideo27",
      "userId": "02860430691370071959"
     },
     "user_tz": -120
    },
    "id": "7371f15f-1500-4596-b778-8342e5dafa9e",
    "outputId": "b4c387d2-92b7-4ca2-fafc-9ecfb8385792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, window_size=60, future_steps=60, batch_size=1, epochs=30, units=12, lstm_layers=2\n",
      "Epoch 1/30\n",
      "4889/4889 [==============================] - 27s 5ms/step - loss: 0.0055 - val_loss: 8.7231e-04\n",
      "Epoch 2/30\n",
      "3908/4889 [======================>.......] - ETA: 4s - loss: 0.0029"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Beispielhafte Ausführung der Funktion\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 81\u001b[0m, in \u001b[0;36mrandom_search\u001b[0;34m(n_iter)\u001b[0m\n\u001b[1;32m     78\u001b[0m earlystop \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Modell trainieren\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearlystop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Vorhersagen auf den Validierungsdaten\u001b[39;00m\n\u001b[1;32m     84\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Jupyter-K0eqoyk3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Jupyter-K0eqoyk3/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Jupyter-K0eqoyk3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Jupyter-K0eqoyk3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Jupyter-K0eqoyk3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Jupyter-K0eqoyk3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Jupyter-K0eqoyk3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Jupyter-K0eqoyk3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Jupyter-K0eqoyk3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Jupyter-K0eqoyk3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Jupyter-K0eqoyk3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Beispielhafte Ausführung der Funktion\n",
    "results = random_search(n_iter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a86a41-c768-4314-b0b5-059bcce4a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_from_models(X_data, y_data, data_type, model_names=None, csv_filename='./results/hyperparameter_search_results.csv', save_fig=True):\n",
    "    \"\"\"\n",
    "    Diese Funktion plotet die Vorhersagen ausgewählter Modelle gegen den echten Kurs.\n",
    "    :param X_data: Die Eingangsdaten (Features).\n",
    "    :param y_data: Die echten Zielwerte (z.B. Aktienkurs).\n",
    "    :param data_type: Typ der Daten ('Train', 'Test').\n",
    "    :param model_names: Liste von Modellnamen oder einzelner Modellname. Wenn None, werden alle Modelle aus der CSV-Datei verwendet.\n",
    "    :param csv_filename: Pfad zur CSV-Datei mit Modellinformationen.\n",
    "    :param save_fig: Wenn True, wird die Figur gespeichert.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Scaler laden\n",
    "    scaler = joblib.load('./scaler/target_scaler.pkl')\n",
    "    \n",
    "    # CSV-Datei laden\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    \n",
    "    # Wenn keine Modellnamen übergeben werden, alle Modelle aus der CSV verwenden\n",
    "    if model_names is None:\n",
    "        model_names = df['Model Name'].tolist()\n",
    "    elif isinstance(model_names, str):  # Falls nur ein einzelner Modellname übergeben wird\n",
    "        model_names = [model_names]\n",
    "\n",
    "    # Rückskalieren der echten Werte\n",
    "    y_data_rescaled = scaler.inverse_transform(y_data.reshape(-1, 1))\n",
    "\n",
    "    # Erstelle einen Plotly-Plot\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Füge die echten Werte hinzu\n",
    "    fig.add_trace(go.Scatter(y=y_data_rescaled.flatten(), mode='lines', name=f'Echte {data_type} Werte', line=dict(color='black')))\n",
    "\n",
    "    # Vorhersagen der ausgewählten Modelle plotten\n",
    "    for model_name in model_names:\n",
    "        if model_name in df['Model Name'].values:\n",
    "            # Extrahiere den window_size und future_steps aus dem Modellnamen (z.B. 'model_20211010-101010_ws30_future5_...')\n",
    "            window_size = int(model_name.split('_ws')[1].split('_')[0])\n",
    "            future_steps = int(model_name.split('_fs')[1].split('_')[0])  # Hier future_steps extrahieren\n",
    "\n",
    "            # Bereite die Daten für das Modell mit der extrahierten window_size vor\n",
    "            X_windowed = create_windowed_data_for_model(X_data, window_size)\n",
    "\n",
    "            # Lade das Modell\n",
    "            model = load_model(f'./models/{model_name}', compile=False)\n",
    "\n",
    "            # Vorhersagen machen\n",
    "            y_pred = model.predict(X_windowed)\n",
    "\n",
    "            # Reshape der y_pred Array für die Rückskalierung basierend auf future_steps\n",
    "            y_pred_reshaped = y_pred.reshape(-1, future_steps)\n",
    "\n",
    "            # Rückskalieren der Vorhersagen\n",
    "            y_pred_rescaled = scaler.inverse_transform(y_pred_reshaped)\n",
    "\n",
    "            # Plot der Vorhersagen für den letzten vorhergesagten Schritt\n",
    "            fig.add_trace(go.Scatter(\n",
    "                y=y_pred_rescaled[:, -1],  # Letzter Vorhersageschritt\n",
    "                mode='lines',\n",
    "                name=f'{model_name} (letzter Schritt)',\n",
    "                line=dict(width=1)\n",
    "            ))\n",
    "\n",
    "            # Optional: Darstellung der Vorhersage über alle zukünftigen Schritte\n",
    "            for step in range(future_steps):\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    y=y_pred_rescaled[:, step],\n",
    "                    mode='lines',\n",
    "                    name=f'{model_name} (Schritt {step+1})',\n",
    "                    line=dict(width=1, dash='dot')\n",
    "                ))\n",
    "\n",
    "        else:\n",
    "            print(f\"Modell {model_name} wurde in der CSV-Datei nicht gefunden.\")\n",
    "\n",
    "    # Layout des Plots\n",
    "    fig.update_layout(\n",
    "        title=f'Vorhersagen der Modelle auf {data_type}daten',\n",
    "        xaxis_title='Zeit',\n",
    "        yaxis_title='Preis',\n",
    "        showlegend=True\n",
    "    )\n",
    "\n",
    "    # Plot anzeigen\n",
    "    fig.show(renderer='browser')\n",
    "    \n",
    "    # Optionales Speichern des Plots\n",
    "    if save_fig:\n",
    "        fig.write_html(f\"./plots/{time.strftime('%Y%m%d-%H%M%S')}.html\")\n",
    "\n",
    "\n",
    "def create_windowed_data_for_model(X_data, window_size):\n",
    "    \"\"\"\n",
    "    Bereitet die Daten so vor, dass sie für Modelle mit unterschiedlicher window_size verwendet werden können.\n",
    "    :param X_data: Originale Daten, die vorfenstert werden sollen.\n",
    "    :param window_size: Die Fenstergröße, die für das Modell verwendet wurde.\n",
    "    :return: Fensterartige Daten für das Modell.\n",
    "    \"\"\"\n",
    "    X_windowed = []\n",
    "    for i in range(window_size, len(X_data)):\n",
    "        X_windowed.append(X_data[i - window_size:i])\n",
    "    return np.array(X_windowed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b268fc-dca3-4d77-8b3c-d36726efcd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_from_models(scaled_features, scaled_target, data_type='Prediction', csv_filename=csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e77d412-7462-4bab-a332-78bf3e04ff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_from_models(scaled_features, scaled_target, data_type='Prediction', model_names=['model_20241011-171432_ws1_bs5_epochs30_units64_layers1.keras'], csv_filename=csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3db64d-0447-429f-99e0-5577929e6854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
