{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f58d2aa4-916f-40e4-acdd-93b10496e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import save_model, load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import joblib\n",
    "\n",
    "# Erstelle den Ordner zum Speichern der Modelle, falls nicht bereits vorhanden\n",
    "os.makedirs('./models', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1cd89d2-67b5-44d3-b7fa-1f88919aaf3b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2257,
     "status": "ok",
     "timestamp": 1728643005227,
     "user": {
      "displayName": "JoVideo27",
      "userId": "02860430691370071959"
     },
     "user_tz": -120
    },
    "id": "b1cd89d2-67b5-44d3-b7fa-1f88919aaf3b",
    "outputId": "28b635c8-8a42-438a-de7f-8100af662fec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low     Close  Adj Close     Volume\n",
      "Date                                                                    \n",
      "2000-01-03  0.936384  1.004464  0.907924  0.999442   0.844004  535796800\n",
      "2000-01-04  0.966518  0.987723  0.903460  0.915179   0.772846  512377600\n",
      "2000-01-05  0.926339  0.987165  0.919643  0.928571   0.784155  778321600\n",
      "2000-01-06  0.947545  0.955357  0.848214  0.848214   0.716296  767972800\n",
      "2000-01-07  0.861607  0.901786  0.852679  0.888393   0.750226  460734400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Lade die historischen Daten einer Aktie (z.B. Apple)\n",
    "symbol = \"AAPL\"  # Apple-Aktien\n",
    "start_date = \"2000-01-01\"  # Startdatum für die Daten\n",
    "end_date = \"2024-10-10\"    # Enddatum für die Daten\n",
    "\n",
    "# CSV-Datei für die Ergebnisse\n",
    "csv_filename = f'./results/hyperparameter_search_results_{start_date}_{end_date}.csv'\n",
    "os.makedirs('./results', exist_ok=True)\n",
    "\n",
    "# Daten herunterladen von Yahoo Finance\n",
    "df = yf.download(symbol, start=start_date, end=end_date)\n",
    "\n",
    "# Überprüfen der Daten\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "637e1447-55ea-4817-b161-af305a5ec846",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 938,
     "status": "ok",
     "timestamp": 1728643006163,
     "user": {
      "displayName": "JoVideo27",
      "userId": "02860430691370071959"
     },
     "user_tz": -120
    },
    "id": "637e1447-55ea-4817-b161-af305a5ec846",
    "outputId": "96c9445c-914f-497c-da63-907bb0321919"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./scaler/target_scaler.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Daten aus den relevanten Spalten entnehmen\n",
    "features = df[['Open', 'High', 'Low', 'Adj Close', 'Volume']]\n",
    "target = df['Close']\n",
    "\n",
    "# MinMaxScaler initialisieren und die Features skalieren\n",
    "feature_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "target_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaled_features = feature_scaler.fit_transform(features)\n",
    "scaled_target = target_scaler.fit_transform(target.values.reshape(-1, 1))\n",
    "\n",
    "joblib.dump(feature_scaler, './scaler/feature_scaler.pkl')\n",
    "joblib.dump(target_scaler, './scaler/target_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df63270f-748e-4faa-af86-6aa47680b434",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1728643009201,
     "user": {
      "displayName": "JoVideo27",
      "userId": "02860430691370071959"
     },
     "user_tz": -120
    },
    "id": "df63270f-748e-4faa-af86-6aa47680b434"
   },
   "outputs": [],
   "source": [
    "val_size= 0.2\n",
    "# Definiere die möglichen Werte für die Hyperparameter\n",
    "hyperparameters = {\n",
    "    'windowsize': [1, 2, 5, 10, 15, 20, 30, 60],\n",
    "    'batchsize': [1, 5, 14, 30, 64, 128, 256, 512],\n",
    "    'epochs': [30],\n",
    "    'units': [1, 2, 5, 6, 8, 12, 16, 32, 64, 128],\n",
    "    'lstm_layers': [1, 2, 3],\n",
    "    'future_steps': [2, 3, 4, 5, 10, 30, 60]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0215dda-2607-4224-a3ef-6e5f29d61da4",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1728643009201,
     "user": {
      "displayName": "JoVideo27",
      "userId": "02860430691370071959"
     },
     "user_tz": -120
    },
    "id": "d0215dda-2607-4224-a3ef-6e5f29d61da4"
   },
   "outputs": [],
   "source": [
    "# Prüfe, ob das Modell bereits existiert\n",
    "def model_exists(window_size, future_steps, batch_size, epochs, units, lstm_layers):\n",
    "    if os.path.exists(csv_filename):\n",
    "        with open(csv_filename, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            for row in reader:\n",
    "                if row[1:6] == [str(window_size), str(future_steps), str(batch_size), str(epochs), str(units), str(lstm_layers)]:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "# Schreibe oder appende die Ergebnisse in die CSV\n",
    "def write_to_csv(model_name, window_size, future_steps, batch_size, epochs, units, lstm_layers, mse, mae, r2):\n",
    "    file_exists = os.path.isfile(csv_filename)\n",
    "    with open(csv_filename, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            # Header hinzufügen, wenn die Datei neu erstellt wird\n",
    "            writer.writerow(['Model Name', 'Window Size', 'Future Steps', 'Batch Size', 'Epochs', 'Units', 'LSTM Layers', 'MSE', 'MAE', 'R2'])\n",
    "        writer.writerow([model_name, window_size, future_steps, batch_size, epochs, units, lstm_layers, mse, mae, r2])\n",
    "\n",
    "def create_sliding_window(data, target, window_size, future_steps):\n",
    "    \"\"\"\n",
    "    Erstellt Sliding-Window-Daten aus den Merkmalen und Zielwerten.\n",
    "    :param data: Skalierte Eingabedaten (Features)\n",
    "    :param target: Skalierte Zielwerte (Target)\n",
    "    :param window_size: Anzahl der vorhergehenden Tage (Fenstergröße)\n",
    "    :param future_steps: Anzahl der Tage in die Zukunft, die vorhergesagt werden\n",
    "    :return: X, y - Arrays mit den Feature-Sequenzen und den Zielwerten\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size - future_steps):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(target[i + window_size:i + window_size + future_steps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# Zufällige Suche über die Hyperparameter\n",
    "def random_search(n_iter=10):\n",
    "    results = []\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        # Zufällige Auswahl von Hyperparametern\n",
    "        window_size = np.random.choice(hyperparameters['windowsize'])\n",
    "        batch_size = np.random.choice(hyperparameters['batchsize'])\n",
    "        epochs = np.random.choice(hyperparameters['epochs'])\n",
    "        units = int(np.random.choice(hyperparameters['units']))\n",
    "        lstm_layers = np.random.choice(hyperparameters['lstm_layers'])\n",
    "        future_steps = np.random.choice(hyperparameters['future_steps'])\n",
    "\n",
    "        print(f\"Iteration: {_}, window_size={window_size}, future_steps={future_steps}, batch_size={batch_size}, epochs={epochs}, units={units}, lstm_layers={lstm_layers}\")\n",
    "\n",
    "        # Prüfe, ob das Modell mit diesen Parametern bereits existiert\n",
    "        if model_exists(window_size, future_steps, batch_size, epochs, units, lstm_layers):\n",
    "            print(f\"Modell mit den Parametern (ws={window_size}, future_steps={future_steps}, bs={batch_size}, ep={epochs}, units={units}, layers={lstm_layers}) existiert bereits. Überspringe...\")\n",
    "            continue\n",
    "\n",
    "        # Daten vorbereiten mit aktuellem window_size und future_steps\n",
    "        X, y = create_sliding_window(scaled_features, scaled_target, window_size=window_size, future_steps=future_steps)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=val_size, random_state=42)\n",
    "\n",
    "        # Modell erstellen\n",
    "        model = Sequential()\n",
    "\n",
    "        # Ersten LSTM Layer hinzufügen\n",
    "        model.add(LSTM(units=units, return_sequences=True if lstm_layers > 1 else False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        # Weitere LSTM Layer falls vorhanden\n",
    "        for layer in range(1, lstm_layers):\n",
    "            model.add(LSTM(units=units, return_sequences=False if layer == lstm_layers - 1 else True))\n",
    "            model.add(Dropout(0.2))\n",
    "\n",
    "        # Dense-Schicht hinzufügen\n",
    "        model.add(Dense(units=future_steps))  # Vorhersage von mehreren Schritten\n",
    "\n",
    "        # Modell kompilieren\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        earlystop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        \n",
    "        # Modell trainieren\n",
    "        history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), verbose=1, callbacks=[earlystop])\n",
    "\n",
    "        # Berechnung der Metriken für den Zeitraum tmax - future_steps bis tmax (gesamter Datensatz)\n",
    "         \n",
    "        # Erstelle X_windowed für den gesamten Datensatz, um Vorhersagen zu machen\n",
    "        X_windowed = create_sliding_window(scaled_features, scaled_target, window_size=window_size, future_steps=future_steps)[0]\n",
    "\n",
    "        # Vorhersagen für die letzten future_steps Datenpunkte im gesamten Datensatz\n",
    "        y_pred = model.predict(X_windowed)  # Vorhersagen auf den letzten verfügbaren Fenstern\n",
    "\n",
    "        # Reshape der y_pred Array für die Rückskalierung basierend auf future_steps\n",
    "        y_pred_reshaped = y_pred.reshape(-1, future_steps)\n",
    "\n",
    "        # Den Skalierungsfaktor rückgängig machen, um die echten Werte wiederherzustellen\n",
    "        y_pred_rescaled = target_scaler.inverse_transform(y_pred_reshaped)\n",
    "\n",
    "        # Bestimme tmax als das Ende des Datensatzes\n",
    "        tmax = len(scaled_target)\n",
    "\n",
    "        # Berechne den Bereich von tmax - future_steps bis tmax (nur die letzten future_steps)\n",
    "        start_idx = tmax - future_steps\n",
    "        end_idx = tmax\n",
    "\n",
    "        # Echte Werte aus dem Gesamt-Datensatz für diesen Zeitraum\n",
    "        y_true_final_span = target_scaler.inverse_transform(scaled_target[start_idx:end_idx].reshape(-1, 1)).flatten()\n",
    "\n",
    "        # Die vorhergesagten Werte für diesen Zeitraum\n",
    "        y_pred_final_span = y_pred_rescaled[-1, :]  # Letzte Vorhersage für die finalen future_steps\n",
    "\n",
    "        # Berechne die Metriken für den Zeitraum tmax - future_steps bis tmax\n",
    "        mse = mean_squared_error(y_true_final_span, y_pred_final_span)\n",
    "        mae = mean_absolute_error(y_true_final_span, y_pred_final_span)\n",
    "        r2 = r2_score(y_true_final_span, y_pred_final_span)\n",
    "\n",
    "        # Ausgabe der Metriken\n",
    "        print(f\"MSE für den Zeitraum tmax - future_steps bis tmax: {mse}\")\n",
    "        print(f\"MAE für den Zeitraum tmax - future_steps bis tmax: {mae}\")\n",
    "        print(f\"R2 für den Zeitraum tmax - future_steps bis tmax: {r2}\")\n",
    "\n",
    "        # Modellname basierend auf einem Zeitstempel\n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        model_name = f\"model_{timestamp}_ws{window_size}_fs{future_steps}_bs{batch_size}_epochs{epochs}_units{units}_layers{lstm_layers}.keras\"\n",
    "        save_model(model, f'./models/{model_name}')\n",
    "\n",
    "        # Ergebnis in die CSV-Datei schreiben\n",
    "        write_to_csv(model_name, window_size, future_steps, batch_size, epochs, units, lstm_layers, mse, mae, r2)\n",
    "\n",
    "        # Ergebnis in die Resultsliste einfügen\n",
    "        results.append((window_size, future_steps, batch_size, epochs, units, lstm_layers, mse, mae, r2, model_name))\n",
    "\n",
    "    # Ergebnisse sortieren nach dem besten MSE\n",
    "    results = sorted(results, key=lambda x: x[5])  # Sortiere nach MSE\n",
    "    best_params = results[0]\n",
    "\n",
    "    print(\"\\nBeste Hyperparameter-Kombination:\")\n",
    "    print(f\"window_size={best_params[0]}, future_steps={best_params[1]}, batch_size={best_params[2]}, epochs={best_params[3]}, units={best_params[4]}, lstm_layers={best_params[5]}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7371f15f-1500-4596-b778-8342e5dafa9e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3396286,
     "status": "ok",
     "timestamp": 1728646405483,
     "user": {
      "displayName": "JoVideo27",
      "userId": "02860430691370071959"
     },
     "user_tz": -120
    },
    "id": "7371f15f-1500-4596-b778-8342e5dafa9e",
    "outputId": "b4c387d2-92b7-4ca2-fafc-9ecfb8385792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, window_size=1, future_steps=5, batch_size=30, epochs=30, units=64, lstm_layers=3\n",
      "Epoch 1/30\n",
      "166/166 [==============================] - 2s 4ms/step - loss: 0.0219 - val_loss: 3.9114e-04\n",
      "Epoch 2/30\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 2.2182e-04\n",
      "Epoch 3/30\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 1.6032e-04\n",
      "Epoch 4/30\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 1.4666e-04\n",
      "Epoch 5/30\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 1.6518e-04\n",
      "Epoch 6/30\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 1.3839e-04\n",
      "Epoch 7/30\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 9.9430e-04 - val_loss: 4.6596e-04\n",
      "Epoch 8/30\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 9.6028e-04 - val_loss: 1.3629e-04\n",
      "Epoch 9/30\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 9.9265e-04 - val_loss: 1.7469e-04\n",
      "Epoch 10/30\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 9.5701e-04 - val_loss: 1.9297e-04\n",
      "Epoch 11/30\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 8.7734e-04 - val_loss: 2.5015e-04\n",
      "Epoch 12/30\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 8.4143e-04 - val_loss: 2.3406e-04\n",
      "Epoch 13/30\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 8.3192e-04 - val_loss: 1.4677e-04\n",
      "Epoch 14/30\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 8.3877e-04 - val_loss: 2.1031e-04\n",
      "Epoch 15/30\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 8.5449e-04 - val_loss: 1.9634e-04\n",
      "Epoch 16/30\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 8.1958e-04 - val_loss: 1.8644e-04\n",
      "Epoch 17/30\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 7.8596e-04 - val_loss: 2.0830e-04\n",
      "Epoch 18/30\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 7.8001e-04 - val_loss: 2.7880e-04\n",
      "195/195 [==============================] - 0s 467us/step\n",
      "MSE für den Zeitraum tmax - future_steps bis tmax: 141.53744794121013\n",
      "MAE für den Zeitraum tmax - future_steps bis tmax: 11.530401611328125\n",
      "R2 für den Zeitraum tmax - future_steps bis tmax: -21.217108480898123\n",
      "Iteration: 1, window_size=5, future_steps=30, batch_size=256, epochs=30, units=8, lstm_layers=3\n",
      "Epoch 1/30\n",
      "20/20 [==============================] - 3s 26ms/step - loss: 0.0831 - val_loss: 0.0716\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0702 - val_loss: 0.0574\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.0389\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0355 - val_loss: 0.0201\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0104\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0059\n",
      "Epoch 7/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0037\n",
      "Epoch 8/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0028\n",
      "Epoch 9/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0022\n",
      "Epoch 10/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0019\n",
      "Epoch 11/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0016\n",
      "Epoch 12/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0014\n",
      "Epoch 13/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0013\n",
      "Epoch 14/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0014\n",
      "Epoch 15/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0012\n",
      "Epoch 16/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0011\n",
      "Epoch 17/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0011\n",
      "Epoch 18/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 9.9841e-04\n",
      "Epoch 19/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 9.8699e-04\n",
      "Epoch 20/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 8.5187e-04\n",
      "Epoch 21/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0010\n",
      "Epoch 22/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 8.3212e-04\n",
      "Epoch 23/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 9.3049e-04\n",
      "Epoch 24/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 9.0493e-04\n",
      "Epoch 25/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 9.5068e-04\n",
      "Epoch 26/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 7.6491e-04\n",
      "Epoch 27/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 7.7930e-04\n",
      "Epoch 28/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 9.5254e-04\n",
      "Epoch 29/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 9.3879e-04\n",
      "Epoch 30/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 8.8532e-04\n",
      "194/194 [==============================] - 1s 559us/step\n",
      "MSE für den Zeitraum tmax - future_steps bis tmax: 1100.6919380143286\n",
      "MAE für den Zeitraum tmax - future_steps bis tmax: 32.69463907877604\n",
      "R2 für den Zeitraum tmax - future_steps bis tmax: -71.07175932032617\n",
      "Iteration: 2, window_size=5, future_steps=30, batch_size=5, epochs=30, units=16, lstm_layers=3\n",
      "Epoch 1/30\n",
      "992/992 [==============================] - 5s 3ms/step - loss: 0.0094 - val_loss: 7.6471e-04\n",
      "Epoch 2/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 7.4634e-04\n",
      "Epoch 3/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 4/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 5.8415e-04\n",
      "Epoch 5/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 5.8840e-04\n",
      "Epoch 6/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 7.1751e-04\n",
      "Epoch 7/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 6.4135e-04\n",
      "Epoch 8/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 5.1667e-04\n",
      "Epoch 9/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 4.6068e-04\n",
      "Epoch 10/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 7.1159e-04\n",
      "Epoch 11/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 5.6711e-04\n",
      "Epoch 12/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 5.3968e-04\n",
      "Epoch 13/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 7.8652e-04\n",
      "Epoch 14/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 15/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 16/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 5.4176e-04\n",
      "Epoch 17/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 5.1551e-04\n",
      "Epoch 18/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 5.1135e-04\n",
      "Epoch 19/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 4.5136e-04\n",
      "Epoch 20/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 8.9151e-04\n",
      "Epoch 21/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 6.0131e-04\n",
      "Epoch 22/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 23/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 4.7117e-04\n",
      "Epoch 24/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 5.9200e-04\n",
      "Epoch 25/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 6.6021e-04\n",
      "Epoch 26/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 5.0357e-04\n",
      "Epoch 27/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 4.2870e-04\n",
      "Epoch 28/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 9.2105e-04\n",
      "Epoch 29/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 5.7243e-04\n",
      "Epoch 30/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 5.4254e-04\n",
      "194/194 [==============================] - 1s 588us/step\n",
      "MSE für den Zeitraum tmax - future_steps bis tmax: 280.51422853122153\n",
      "MAE für den Zeitraum tmax - future_steps bis tmax: 16.35753479003906\n",
      "R2 für den Zeitraum tmax - future_steps bis tmax: -17.36767697336036\n",
      "Iteration: 3, window_size=15, future_steps=10, batch_size=256, epochs=30, units=16, lstm_layers=3\n",
      "Epoch 1/30\n",
      "20/20 [==============================] - 3s 31ms/step - loss: 0.0744 - val_loss: 0.0453\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0337 - val_loss: 0.0090\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0025\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0018\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0013\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0013\n",
      "Epoch 7/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 7.8104e-04\n",
      "Epoch 8/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 7.9429e-04\n",
      "Epoch 9/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 7.6981e-04\n",
      "Epoch 10/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 5.5654e-04\n",
      "Epoch 11/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 6.6907e-04\n",
      "Epoch 12/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 7.3579e-04\n",
      "Epoch 13/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 5.4596e-04\n",
      "Epoch 14/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 5.2255e-04\n",
      "Epoch 15/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 5.9876e-04\n",
      "Epoch 16/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 4.2243e-04\n",
      "Epoch 17/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 3.8582e-04\n",
      "Epoch 18/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 3.6467e-04\n",
      "Epoch 19/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 3.3986e-04\n",
      "Epoch 20/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 3.2227e-04\n",
      "Epoch 21/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 6.7328e-04\n",
      "Epoch 22/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 3.1871e-04\n",
      "Epoch 23/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 3.5273e-04\n",
      "Epoch 24/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 3.1266e-04\n",
      "Epoch 25/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 2.7162e-04\n",
      "Epoch 26/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 4.3388e-04\n",
      "Epoch 27/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 2.5871e-04\n",
      "Epoch 28/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 3.6378e-04\n",
      "Epoch 29/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 2.8221e-04\n",
      "Epoch 30/30\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 2.8661e-04\n",
      "194/194 [==============================] - 1s 985us/step\n",
      "MSE für den Zeitraum tmax - future_steps bis tmax: 219.85473646372557\n",
      "MAE für den Zeitraum tmax - future_steps bis tmax: 14.42733154296875\n",
      "R2 für den Zeitraum tmax - future_steps bis tmax: -28.12865758099794\n",
      "Iteration: 4, window_size=60, future_steps=30, batch_size=512, epochs=30, units=128, lstm_layers=2\n",
      "Epoch 1/30\n",
      "10/10 [==============================] - 4s 267ms/step - loss: 0.0410 - val_loss: 0.0070\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 0.0080 - val_loss: 0.0022\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 0.0049 - val_loss: 0.0012\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 0.0037 - val_loss: 8.4238e-04\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.0032 - val_loss: 6.8918e-04\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 0.0030 - val_loss: 5.5262e-04\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.0027 - val_loss: 5.3513e-04\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.0026 - val_loss: 5.7496e-04\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.0024 - val_loss: 6.0366e-04\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.0023 - val_loss: 4.7546e-04\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.0022 - val_loss: 4.8201e-04\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.0021 - val_loss: 5.9017e-04\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.0020 - val_loss: 4.7320e-04\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 0.0019 - val_loss: 4.8113e-04\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.0018 - val_loss: 5.5699e-04\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.0018 - val_loss: 4.6641e-04\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.0018 - val_loss: 4.5313e-04\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.0017 - val_loss: 4.8276e-04\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 0.0017 - val_loss: 4.8245e-04\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.0016 - val_loss: 5.2504e-04\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.0016 - val_loss: 4.5019e-04\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.0015 - val_loss: 6.4629e-04\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.0016 - val_loss: 4.4742e-04\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.0014 - val_loss: 4.5997e-04\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.0015 - val_loss: 4.8019e-04\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.0013 - val_loss: 4.9794e-04\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.0014 - val_loss: 4.4219e-04\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.0014 - val_loss: 4.7639e-04\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.0014 - val_loss: 4.4050e-04\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 3s 294ms/step - loss: 0.0013 - val_loss: 4.4074e-04\n",
      "192/192 [==============================] - 3s 13ms/step\n",
      "MSE für den Zeitraum tmax - future_steps bis tmax: 30.994855837935273\n",
      "MAE für den Zeitraum tmax - future_steps bis tmax: 4.664152526855469\n",
      "R2 für den Zeitraum tmax - future_steps bis tmax: -1.029499547484464\n",
      "Iteration: 5, window_size=60, future_steps=60, batch_size=64, epochs=30, units=12, lstm_layers=2\n",
      "Epoch 1/30\n",
      "77/77 [==============================] - 2s 14ms/step - loss: 0.0510 - val_loss: 0.0094\n",
      "Epoch 2/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0092 - val_loss: 0.0019\n",
      "Epoch 3/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0058 - val_loss: 0.0013\n",
      "Epoch 4/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0048 - val_loss: 0.0011\n",
      "Epoch 5/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0043 - val_loss: 9.9619e-04\n",
      "Epoch 6/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 7/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0035 - val_loss: 8.1659e-04\n",
      "Epoch 8/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0033 - val_loss: 8.7110e-04\n",
      "Epoch 9/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0032 - val_loss: 8.2334e-04\n",
      "Epoch 10/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 11/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 12/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0028 - val_loss: 8.0514e-04\n",
      "Epoch 13/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0026 - val_loss: 7.8188e-04\n",
      "Epoch 14/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 15/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0025 - val_loss: 8.4516e-04\n",
      "Epoch 16/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0026 - val_loss: 9.2421e-04\n",
      "Epoch 17/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0024 - val_loss: 8.1483e-04\n",
      "Epoch 18/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0025 - val_loss: 7.6612e-04\n",
      "Epoch 19/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0023 - val_loss: 7.6193e-04\n",
      "Epoch 20/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0024 - val_loss: 8.9145e-04\n",
      "Epoch 21/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0024 - val_loss: 8.5100e-04\n",
      "Epoch 22/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0022 - val_loss: 8.5054e-04\n",
      "Epoch 23/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0022 - val_loss: 7.7161e-04\n",
      "Epoch 24/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0023 - val_loss: 7.5696e-04\n",
      "Epoch 25/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0023 - val_loss: 8.6752e-04\n",
      "Epoch 26/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 27/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0023 - val_loss: 7.9217e-04\n",
      "Epoch 28/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0022 - val_loss: 7.7832e-04\n",
      "Epoch 29/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0023 - val_loss: 9.2828e-04\n",
      "Epoch 30/30\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0022 - val_loss: 7.9119e-04\n",
      "191/191 [==============================] - 1s 2ms/step\n",
      "MSE für den Zeitraum tmax - future_steps bis tmax: 190.73848805339853\n",
      "MAE für den Zeitraum tmax - future_steps bis tmax: 13.030067952473958\n",
      "R2 für den Zeitraum tmax - future_steps bis tmax: -6.017166276830435\n",
      "Iteration: 6, window_size=5, future_steps=4, batch_size=128, epochs=30, units=8, lstm_layers=3\n",
      "Epoch 1/30\n",
      "39/39 [==============================] - 3s 14ms/step - loss: 0.0800 - val_loss: 0.0576\n",
      "Epoch 2/30\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0237\n",
      "Epoch 3/30\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0028\n",
      "Epoch 4/30\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0012\n",
      "Epoch 5/30\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0013\n",
      "Epoch 6/30\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0011\n",
      "Epoch 7/30\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 8.0904e-04\n",
      "Epoch 8/30\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 7.7716e-04\n",
      "Epoch 9/30\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 7.4767e-04\n",
      "Epoch 10/30\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 7.5293e-04\n",
      "Epoch 11/30\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 6.5280e-04\n",
      "Epoch 12/30\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 6.1987e-04\n",
      "Epoch 13/30\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 6.1058e-04\n",
      "Epoch 14/30\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 4.8941e-04\n",
      "Epoch 15/30\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 4.0273e-04\n",
      "Epoch 16/30\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 6.8495e-04\n",
      "Epoch 17/30\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 4.5948e-04\n",
      "Epoch 18/30\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 3.9401e-04\n",
      "Epoch 19/30\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 3.8882e-04\n",
      "Epoch 20/30\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 5.4035e-04\n",
      "Epoch 21/30\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 4.2209e-04\n",
      "Epoch 22/30\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 3.9437e-04\n",
      "Epoch 23/30\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 2.9493e-04\n",
      "Epoch 24/30\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 3.3744e-04\n",
      "Epoch 25/30\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 2.9509e-04\n",
      "Epoch 26/30\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 3.1285e-04\n",
      "Epoch 27/30\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 4.2828e-04\n",
      "Epoch 28/30\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 2.8615e-04\n",
      "Epoch 29/30\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 4.2481e-04\n",
      "Epoch 30/30\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 3.7350e-04\n",
      "195/195 [==============================] - 1s 584us/step\n",
      "MSE für den Zeitraum tmax - future_steps bis tmax: 458.7111862550955\n",
      "MAE für den Zeitraum tmax - future_steps bis tmax: 21.24547576904297\n",
      "R2 für den Zeitraum tmax - future_steps bis tmax: -56.71669981611907\n",
      "Iteration: 7, window_size=1, future_steps=5, batch_size=5, epochs=30, units=32, lstm_layers=1\n",
      "Epoch 1/30\n",
      "996/996 [==============================] - 1s 690us/step - loss: 0.0082 - val_loss: 1.9180e-04\n",
      "Epoch 2/30\n",
      "996/996 [==============================] - 1s 513us/step - loss: 0.0012 - val_loss: 1.9522e-04\n",
      "Epoch 3/30\n",
      "996/996 [==============================] - 1s 516us/step - loss: 9.7368e-04 - val_loss: 2.4946e-04\n",
      "Epoch 4/30\n",
      "996/996 [==============================] - 1s 521us/step - loss: 7.3790e-04 - val_loss: 1.0212e-04\n",
      "Epoch 5/30\n",
      "996/996 [==============================] - 1s 512us/step - loss: 7.1563e-04 - val_loss: 9.4472e-05\n",
      "Epoch 6/30\n",
      "996/996 [==============================] - 1s 510us/step - loss: 6.9113e-04 - val_loss: 1.2600e-04\n",
      "Epoch 7/30\n",
      "996/996 [==============================] - 1s 507us/step - loss: 6.4856e-04 - val_loss: 1.4224e-04\n",
      "Epoch 8/30\n",
      "996/996 [==============================] - 1s 509us/step - loss: 6.4196e-04 - val_loss: 1.6022e-04\n",
      "Epoch 9/30\n",
      "996/996 [==============================] - 1s 505us/step - loss: 6.3381e-04 - val_loss: 1.2259e-04\n",
      "Epoch 10/30\n",
      "996/996 [==============================] - 1s 503us/step - loss: 6.3542e-04 - val_loss: 3.9704e-04\n",
      "Epoch 11/30\n",
      "996/996 [==============================] - 0s 491us/step - loss: 6.4708e-04 - val_loss: 9.0857e-05\n",
      "Epoch 12/30\n",
      "996/996 [==============================] - 1s 518us/step - loss: 6.0069e-04 - val_loss: 1.4132e-04\n",
      "Epoch 13/30\n",
      "996/996 [==============================] - 1s 520us/step - loss: 6.7266e-04 - val_loss: 1.1067e-04\n",
      "Epoch 14/30\n",
      "996/996 [==============================] - 1s 528us/step - loss: 6.5173e-04 - val_loss: 9.4173e-05\n",
      "Epoch 15/30\n",
      "996/996 [==============================] - 1s 523us/step - loss: 6.1700e-04 - val_loss: 1.2686e-04\n",
      "Epoch 16/30\n",
      "996/996 [==============================] - 1s 512us/step - loss: 6.1715e-04 - val_loss: 1.5998e-04\n",
      "Epoch 17/30\n",
      "996/996 [==============================] - 1s 512us/step - loss: 5.7636e-04 - val_loss: 1.1107e-04\n",
      "Epoch 18/30\n",
      "996/996 [==============================] - 1s 508us/step - loss: 6.5202e-04 - val_loss: 1.2860e-04\n",
      "Epoch 19/30\n",
      "996/996 [==============================] - 1s 515us/step - loss: 5.7679e-04 - val_loss: 1.2436e-04\n",
      "Epoch 20/30\n",
      "996/996 [==============================] - 1s 513us/step - loss: 6.5818e-04 - val_loss: 1.7763e-04\n",
      "Epoch 21/30\n",
      "996/996 [==============================] - 1s 507us/step - loss: 6.1147e-04 - val_loss: 1.3387e-04\n",
      "195/195 [==============================] - 0s 298us/step\n",
      "MSE für den Zeitraum tmax - future_steps bis tmax: 6.186197339976206\n",
      "MAE für den Zeitraum tmax - future_steps bis tmax: 1.9428680419921875\n",
      "R2 für den Zeitraum tmax - future_steps bis tmax: 0.02895368409085297\n",
      "Iteration: 8, window_size=1, future_steps=60, batch_size=30, epochs=30, units=128, lstm_layers=1\n",
      "Epoch 1/30\n",
      "165/165 [==============================] - 1s 2ms/step - loss: 0.0184 - val_loss: 8.6315e-04\n",
      "Epoch 2/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 7.8224e-04\n",
      "Epoch 3/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 8.4693e-04\n",
      "Epoch 4/30\n",
      "165/165 [==============================] - 0s 997us/step - loss: 0.0012 - val_loss: 7.2023e-04\n",
      "Epoch 5/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 6.8532e-04\n",
      "Epoch 6/30\n",
      "165/165 [==============================] - 0s 977us/step - loss: 0.0011 - val_loss: 6.6630e-04\n",
      "Epoch 7/30\n",
      "165/165 [==============================] - 0s 978us/step - loss: 0.0010 - val_loss: 6.5685e-04\n",
      "Epoch 8/30\n",
      "165/165 [==============================] - 0s 988us/step - loss: 0.0010 - val_loss: 6.5894e-04\n",
      "Epoch 9/30\n",
      "165/165 [==============================] - 0s 973us/step - loss: 0.0010 - val_loss: 7.0258e-04\n",
      "Epoch 10/30\n",
      "165/165 [==============================] - 0s 980us/step - loss: 0.0010 - val_loss: 6.8630e-04\n",
      "Epoch 11/30\n",
      "165/165 [==============================] - 0s 984us/step - loss: 0.0010 - val_loss: 6.6533e-04\n",
      "Epoch 12/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 7.4314e-04\n",
      "Epoch 13/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 9.6619e-04 - val_loss: 6.5659e-04\n",
      "Epoch 14/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 9.6061e-04 - val_loss: 7.0886e-04\n",
      "Epoch 15/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 9.6602e-04 - val_loss: 8.5999e-04\n",
      "Epoch 16/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 9.9118e-04 - val_loss: 6.5104e-04\n",
      "Epoch 17/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 9.4305e-04 - val_loss: 6.8356e-04\n",
      "Epoch 18/30\n",
      "165/165 [==============================] - 0s 994us/step - loss: 9.4211e-04 - val_loss: 6.7047e-04\n",
      "Epoch 19/30\n",
      "165/165 [==============================] - 0s 986us/step - loss: 9.0920e-04 - val_loss: 7.6660e-04\n",
      "Epoch 20/30\n",
      "165/165 [==============================] - 0s 992us/step - loss: 9.2182e-04 - val_loss: 6.8804e-04\n",
      "Epoch 21/30\n",
      "165/165 [==============================] - 0s 998us/step - loss: 9.0526e-04 - val_loss: 6.9130e-04\n",
      "Epoch 22/30\n",
      "165/165 [==============================] - 0s 986us/step - loss: 9.0839e-04 - val_loss: 6.4873e-04\n",
      "Epoch 23/30\n",
      "165/165 [==============================] - 0s 995us/step - loss: 8.9677e-04 - val_loss: 6.4726e-04\n",
      "Epoch 24/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 8.9996e-04 - val_loss: 6.9829e-04\n",
      "Epoch 25/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 9.2349e-04 - val_loss: 6.9197e-04\n",
      "Epoch 26/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 9.3539e-04 - val_loss: 6.4619e-04\n",
      "Epoch 27/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 8.9049e-04 - val_loss: 6.6100e-04\n",
      "Epoch 28/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 8.9790e-04 - val_loss: 6.7979e-04\n",
      "Epoch 29/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 9.0368e-04 - val_loss: 6.6164e-04\n",
      "Epoch 30/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 8.8648e-04 - val_loss: 6.4902e-04\n",
      "193/193 [==============================] - 0s 410us/step\n",
      "MSE für den Zeitraum tmax - future_steps bis tmax: 76.83380723772183\n",
      "MAE für den Zeitraum tmax - future_steps bis tmax: 7.319856516520182\n",
      "R2 für den Zeitraum tmax - future_steps bis tmax: -1.8266743989188563\n",
      "Iteration: 9, window_size=15, future_steps=60, batch_size=5, epochs=30, units=64, lstm_layers=1\n",
      "Epoch 1/30\n",
      "985/985 [==============================] - 2s 2ms/step - loss: 0.0045 - val_loss: 0.0016\n",
      "Epoch 2/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0017 - val_loss: 7.6421e-04\n",
      "Epoch 3/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0014 - val_loss: 7.6098e-04\n",
      "Epoch 4/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0013 - val_loss: 8.4117e-04\n",
      "Epoch 5/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0012 - val_loss: 7.4323e-04\n",
      "Epoch 6/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 8.5624e-04\n",
      "Epoch 7/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0012 - val_loss: 7.7907e-04\n",
      "Epoch 8/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 9/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 8.0989e-04\n",
      "Epoch 10/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 7.9862e-04\n",
      "Epoch 11/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 7.1724e-04\n",
      "Epoch 12/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0010 - val_loss: 7.1859e-04\n",
      "Epoch 13/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 7.0764e-04\n",
      "Epoch 14/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 7.5330e-04\n",
      "Epoch 15/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 8.1098e-04\n",
      "Epoch 16/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 7.6131e-04\n",
      "Epoch 17/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 7.1145e-04\n",
      "Epoch 18/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 7.2332e-04\n",
      "Epoch 19/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 20/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 7.2413e-04\n",
      "Epoch 21/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 22/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0010 - val_loss: 7.0050e-04\n",
      "Epoch 23/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0010 - val_loss: 7.3054e-04\n",
      "Epoch 24/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 7.1075e-04\n",
      "Epoch 25/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 7.2080e-04\n",
      "Epoch 26/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 9.6145e-04 - val_loss: 8.8695e-04\n",
      "Epoch 27/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0010 - val_loss: 7.6980e-04\n",
      "Epoch 28/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 7.1141e-04\n",
      "Epoch 29/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0010 - val_loss: 7.3131e-04\n",
      "Epoch 30/30\n",
      "985/985 [==============================] - 1s 1ms/step - loss: 0.0010 - val_loss: 9.5776e-04\n",
      "193/193 [==============================] - 0s 820us/step\n",
      "MSE für den Zeitraum tmax - future_steps bis tmax: 142.6830375303553\n",
      "MAE für den Zeitraum tmax - future_steps bis tmax: 10.922054290771484\n",
      "R2 für den Zeitraum tmax - future_steps bis tmax: -4.249232126415091\n",
      "Iteration: 10, window_size=60, future_steps=5, batch_size=64, epochs=30, units=6, lstm_layers=3\n",
      "Epoch 1/30\n",
      "78/78 [==============================] - 4s 20ms/step - loss: 0.0610 - val_loss: 0.0100\n",
      "Epoch 2/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0139 - val_loss: 0.0024\n",
      "Epoch 3/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0103 - val_loss: 0.0021\n",
      "Epoch 4/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0089 - val_loss: 0.0011\n",
      "Epoch 5/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0074 - val_loss: 0.0020\n",
      "Epoch 6/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0074 - val_loss: 6.7873e-04\n",
      "Epoch 7/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0060 - val_loss: 0.0010\n",
      "Epoch 8/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0056 - val_loss: 7.2397e-04\n",
      "Epoch 9/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0054 - val_loss: 6.3753e-04\n",
      "Epoch 10/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0048 - val_loss: 7.5283e-04\n",
      "Epoch 11/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0049 - val_loss: 8.5592e-04\n",
      "Epoch 12/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0044 - val_loss: 8.8338e-04\n",
      "Epoch 13/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0045 - val_loss: 6.1662e-04\n",
      "Epoch 14/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0044 - val_loss: 3.7227e-04\n",
      "Epoch 15/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0043 - val_loss: 4.5823e-04\n",
      "Epoch 16/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0040 - val_loss: 4.2619e-04\n",
      "Epoch 17/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0039 - val_loss: 9.7659e-04\n",
      "Epoch 18/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0040 - val_loss: 5.5645e-04\n",
      "Epoch 19/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0037 - val_loss: 3.6529e-04\n",
      "Epoch 20/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0036 - val_loss: 7.2928e-04\n",
      "Epoch 21/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0037 - val_loss: 3.5274e-04\n",
      "Epoch 22/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0034 - val_loss: 3.7609e-04\n",
      "Epoch 23/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0037 - val_loss: 3.7633e-04\n",
      "Epoch 24/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0035 - val_loss: 3.1212e-04\n",
      "Epoch 25/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0035 - val_loss: 3.3089e-04\n",
      "Epoch 26/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0033 - val_loss: 3.8595e-04\n",
      "Epoch 27/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0033 - val_loss: 4.3864e-04\n",
      "Epoch 28/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0035 - val_loss: 4.4598e-04\n",
      "Epoch 29/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0032 - val_loss: 4.8597e-04\n",
      "Epoch 30/30\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.0030 - val_loss: 3.2161e-04\n",
      "193/193 [==============================] - 1s 2ms/step\n",
      "MSE für den Zeitraum tmax - future_steps bis tmax: 194.13989789835176\n",
      "MAE für den Zeitraum tmax - future_steps bis tmax: 13.614401245117188\n",
      "R2 für den Zeitraum tmax - future_steps bis tmax: -29.474105862568155\n",
      "Iteration: 11, window_size=60, future_steps=5, batch_size=512, epochs=30, units=32, lstm_layers=3\n",
      "Epoch 1/30\n",
      "10/10 [==============================] - 4s 242ms/step - loss: 0.0466 - val_loss: 0.0116\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0106 - val_loss: 0.0035\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0068 - val_loss: 9.6344e-04\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0047 - val_loss: 9.2235e-04\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0044 - val_loss: 5.8419e-04\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0041 - val_loss: 4.9622e-04\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0037 - val_loss: 6.5201e-04\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0038 - val_loss: 4.3547e-04\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0037 - val_loss: 4.0997e-04\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0034 - val_loss: 5.4870e-04\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0033 - val_loss: 5.0157e-04\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0032 - val_loss: 3.9703e-04\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0030 - val_loss: 4.6896e-04\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0033 - val_loss: 4.8461e-04\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0030 - val_loss: 4.1531e-04\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0029 - val_loss: 4.0814e-04\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 0.0026 - val_loss: 3.0979e-04\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0026 - val_loss: 3.3105e-04\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0025 - val_loss: 2.9978e-04\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 0.0025 - val_loss: 3.0831e-04\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 1s 151ms/step - loss: 0.0024 - val_loss: 2.7665e-04\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0024 - val_loss: 3.0806e-04\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0023 - val_loss: 2.7170e-04\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0023 - val_loss: 2.6115e-04\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 0.0023 - val_loss: 2.9648e-04\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 0.0021 - val_loss: 3.0268e-04\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 0.0021 - val_loss: 2.5069e-04\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0021 - val_loss: 2.4635e-04\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0020 - val_loss: 2.4293e-04\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0020 - val_loss: 2.5231e-04\n",
      "193/193 [==============================] - 1s 4ms/step\n",
      "MSE für den Zeitraum tmax - future_steps bis tmax: 126.85626153997146\n",
      "MAE für den Zeitraum tmax - future_steps bis tmax: 11.074319458007812\n",
      "R2 für den Zeitraum tmax - future_steps bis tmax: -18.912605215867604\n",
      "Iteration: 12, window_size=1, future_steps=10, batch_size=256, epochs=30, units=12, lstm_layers=3\n",
      "Epoch 1/30\n",
      "20/20 [==============================] - 2s 24ms/step - loss: 0.0868 - val_loss: 0.0795\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0714\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0629\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0606 - val_loss: 0.0534\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0410\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0350 - val_loss: 0.0224\n",
      "Epoch 7/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0070\n",
      "Epoch 8/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0026\n",
      "Epoch 9/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0018\n",
      "Epoch 10/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0012\n",
      "Epoch 11/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0011\n",
      "Epoch 12/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 9.2870e-04\n",
      "Epoch 13/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 6.9933e-04\n",
      "Epoch 14/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 6.0890e-04\n",
      "Epoch 15/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 7.0485e-04\n",
      "Epoch 16/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 5.4380e-04\n",
      "Epoch 17/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 5.7380e-04\n",
      "Epoch 18/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 6.2083e-04\n",
      "Epoch 19/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 5.9518e-04\n",
      "Epoch 20/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 6.4228e-04\n",
      "Epoch 21/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 6.0499e-04\n",
      "Epoch 22/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 6.4995e-04\n",
      "Epoch 23/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 5.9730e-04\n",
      "Epoch 24/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 5.7542e-04\n",
      "Epoch 25/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 5.7200e-04\n",
      "Epoch 26/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 6.8813e-04\n",
      "195/195 [==============================] - 0s 431us/step\n",
      "MSE für den Zeitraum tmax - future_steps bis tmax: 733.9239923648769\n",
      "MAE für den Zeitraum tmax - future_steps bis tmax: 26.919596862792968\n",
      "R2 für den Zeitraum tmax - future_steps bis tmax: -96.23793541106036\n",
      "Iteration: 13, window_size=30, future_steps=3, batch_size=5, epochs=30, units=8, lstm_layers=1\n",
      "Epoch 1/30\n",
      "992/992 [==============================] - 4s 3ms/step - loss: 0.0076 - val_loss: 3.1466e-04\n",
      "Epoch 2/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0033 - val_loss: 1.9171e-04\n",
      "Epoch 3/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 3.6290e-04\n",
      "Epoch 4/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 1.6735e-04\n",
      "Epoch 5/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 1.4473e-04\n",
      "Epoch 6/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 1.4028e-04\n",
      "Epoch 7/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 2.2501e-04\n",
      "Epoch 8/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 2.1593e-04\n",
      "Epoch 9/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 1.1379e-04\n",
      "Epoch 10/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 1.7276e-04\n",
      "Epoch 11/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 3.3817e-04\n",
      "Epoch 12/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 8.9483e-05\n",
      "Epoch 13/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 9.7902e-05\n",
      "Epoch 14/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 2.0224e-04\n",
      "Epoch 15/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 5.4802e-04\n",
      "Epoch 16/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 2.7278e-04\n",
      "Epoch 17/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 3.2942e-04\n",
      "Epoch 18/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 1.1401e-04\n",
      "Epoch 19/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 1.6216e-04\n",
      "Epoch 20/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 1.5678e-04\n",
      "Epoch 21/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 7.3187e-05\n",
      "Epoch 22/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 6.9313e-05\n",
      "Epoch 23/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 4.0121e-04\n",
      "Epoch 24/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 2.9621e-04\n",
      "Epoch 25/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 8.8759e-05\n",
      "Epoch 26/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 1.6719e-04\n",
      "Epoch 27/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 1.4627e-04\n",
      "Epoch 28/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 1.9378e-04\n",
      "Epoch 29/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 1.5769e-04\n",
      "Epoch 30/30\n",
      "992/992 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 7.7813e-05\n",
      "194/194 [==============================] - 0s 615us/step\n",
      "MSE für den Zeitraum tmax - future_steps bis tmax: 26.286136945243925\n",
      "MAE für den Zeitraum tmax - future_steps bis tmax: 4.30291748046875\n",
      "R2 für den Zeitraum tmax - future_steps bis tmax: -1.5580792532305776\n",
      "Iteration: 14, window_size=20, future_steps=4, batch_size=1, epochs=30, units=32, lstm_layers=3\n",
      "Epoch 1/30\n",
      "4966/4966 [==============================] - 19s 4ms/step - loss: 0.0037 - val_loss: 5.3854e-04\n",
      "Epoch 2/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 0.0019 - val_loss: 2.0325e-04\n",
      "Epoch 3/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 0.0015 - val_loss: 2.4002e-04\n",
      "Epoch 4/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 0.0015 - val_loss: 6.7640e-04\n",
      "Epoch 5/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 6/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 0.0014 - val_loss: 5.3742e-04\n",
      "Epoch 7/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 0.0012 - val_loss: 3.8073e-04\n",
      "Epoch 8/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 0.0012 - val_loss: 1.8697e-04\n",
      "Epoch 9/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 0.0012 - val_loss: 7.9638e-04\n",
      "Epoch 10/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 0.0010 - val_loss: 3.2548e-04\n",
      "Epoch 11/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 12/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 0.0011 - val_loss: 1.5130e-04\n",
      "Epoch 13/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 0.0010 - val_loss: 1.1331e-04\n",
      "Epoch 14/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 9.5981e-04 - val_loss: 9.5055e-05\n",
      "Epoch 15/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 9.5820e-04 - val_loss: 3.0802e-04\n",
      "Epoch 16/30\n",
      "4966/4966 [==============================] - 16s 3ms/step - loss: 9.9900e-04 - val_loss: 4.9917e-04\n",
      "Epoch 17/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 9.6233e-04 - val_loss: 1.4750e-04\n",
      "Epoch 18/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 0.0010 - val_loss: 3.0018e-04\n",
      "Epoch 19/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 9.6494e-04 - val_loss: 1.7159e-04\n",
      "Epoch 20/30\n",
      "4966/4966 [==============================] - 16s 3ms/step - loss: 9.5242e-04 - val_loss: 2.9798e-04\n",
      "Epoch 21/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 8.7677e-04 - val_loss: 1.4207e-04\n",
      "Epoch 22/30\n",
      "4966/4966 [==============================] - 17s 3ms/step - loss: 8.9773e-04 - val_loss: 2.4610e-04\n",
      "Epoch 23/30\n",
      "4966/4966 [==============================] - 16s 3ms/step - loss: 8.6171e-04 - val_loss: 3.0380e-04\n",
      "Epoch 24/30\n",
      "4966/4966 [==============================] - 16s 3ms/step - loss: 9.2302e-04 - val_loss: 2.1285e-04\n",
      "194/194 [==============================] - 1s 2ms/step\n",
      "MSE für den Zeitraum tmax - future_steps bis tmax: 5.155814838479273\n",
      "MAE für den Zeitraum tmax - future_steps bis tmax: 1.7660980224609375\n",
      "R2 für den Zeitraum tmax - future_steps bis tmax: 0.35127673739677623\n",
      "Iteration: 15, window_size=60, future_steps=3, batch_size=128, epochs=30, units=2, lstm_layers=2\n",
      "Epoch 1/30\n",
      "39/39 [==============================] - 2s 17ms/step - loss: 0.0955 - val_loss: 0.0698\n",
      "Epoch 2/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0662 - val_loss: 0.0518\n",
      "Epoch 3/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0528 - val_loss: 0.0411\n",
      "Epoch 4/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0434 - val_loss: 0.0314\n",
      "Epoch 5/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0348 - val_loss: 0.0226\n",
      "Epoch 6/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0276 - val_loss: 0.0156\n",
      "Epoch 7/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0114\n",
      "Epoch 8/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0086\n",
      "Epoch 9/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0072\n",
      "Epoch 10/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.0056\n",
      "Epoch 11/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0049\n",
      "Epoch 12/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0042\n",
      "Epoch 13/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0037\n",
      "Epoch 14/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0033\n",
      "Epoch 15/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0028\n",
      "Epoch 16/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0029\n",
      "Epoch 17/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0027\n",
      "Epoch 18/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0025\n",
      "Epoch 19/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0022\n",
      "Epoch 20/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0023\n",
      "Epoch 21/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0020\n",
      "Epoch 22/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0021\n",
      "Epoch 23/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0018\n",
      "Epoch 24/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0017\n",
      "Epoch 25/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0016\n",
      "Epoch 26/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0016\n",
      "Epoch 27/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0014\n",
      "Epoch 28/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0015\n",
      "Epoch 29/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0017\n",
      "Epoch 30/30\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0013\n",
      "193/193 [==============================] - 1s 2ms/step\n",
      "MSE für den Zeitraum tmax - future_steps bis tmax: 1790.729036661253\n",
      "MAE für den Zeitraum tmax - future_steps bis tmax: 42.27912902832031\n",
      "R2 für den Zeitraum tmax - future_steps bis tmax: -173.267782534305\n",
      "Iteration: 16, window_size=15, future_steps=60, batch_size=30, epochs=30, units=2, lstm_layers=1\n",
      "Epoch 1/30\n",
      "165/165 [==============================] - 2s 3ms/step - loss: 0.0576 - val_loss: 0.0264\n",
      "Epoch 2/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0071\n",
      "Epoch 3/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0037\n",
      "Epoch 4/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0026\n",
      "Epoch 5/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0020\n",
      "Epoch 6/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0019\n",
      "Epoch 7/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0019\n",
      "Epoch 8/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0018\n",
      "Epoch 9/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0019\n",
      "Epoch 10/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0019\n",
      "Epoch 11/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0017\n",
      "Epoch 12/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0017\n",
      "Epoch 13/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0016\n",
      "Epoch 14/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0019\n",
      "Epoch 15/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0015\n",
      "Epoch 16/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0013\n",
      "Epoch 17/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0017\n",
      "Epoch 18/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0016\n",
      "Epoch 19/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0015\n",
      "Epoch 20/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0017\n",
      "Epoch 21/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0017\n",
      "Epoch 22/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0016\n",
      "Epoch 23/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0015\n",
      "Epoch 24/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0017\n",
      "Epoch 25/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0019\n",
      "Epoch 26/30\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0015\n",
      "193/193 [==============================] - 0s 426us/step\n",
      "MSE für den Zeitraum tmax - future_steps bis tmax: 1389.2201662626856\n",
      "MAE für den Zeitraum tmax - future_steps bis tmax: 36.95480066935222\n",
      "R2 für den Zeitraum tmax - future_steps bis tmax: -50.10866192387012\n",
      "Iteration: 17, window_size=20, future_steps=4, batch_size=1, epochs=30, units=32, lstm_layers=2\n",
      "Epoch 1/30\n",
      "4966/4966 [==============================] - 13s 2ms/step - loss: 0.0033 - val_loss: 4.2565e-04\n",
      "Epoch 2/30\n",
      "1568/4966 [========>.....................] - ETA: 7s - loss: 0.0019"
     ]
    }
   ],
   "source": [
    "# Beispielhafte Ausführung der Funktion\n",
    "results = random_search(n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a86a41-c768-4314-b0b5-059bcce4a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.colors as pc\n",
    "\n",
    "def plot_predictions_from_models(X_data, y_data, data_type, dates, model_names=None, csv_filename='./results/hyperparameter_search_results.csv', save_fig=True):\n",
    "    \"\"\"\n",
    "    Diese Funktion plotet die Vorhersagen ausgewählter Modelle gegen den echten Kurs.\n",
    "    :param X_data: Die Eingangsdaten (Features).\n",
    "    :param y_data: Die echten Zielwerte (z.B. Aktienkurs).\n",
    "    :param data_type: Typ der Daten ('Train', 'Test').\n",
    "    :param dates: Liste oder Serie der Datumswerte (X-Achse).\n",
    "    :param model_names: Liste von Modellnamen oder einzelner Modellname. Wenn None, werden alle Modelle aus der CSV-Datei verwendet.\n",
    "    :param csv_filename: Pfad zur CSV-Datei mit Modellinformationen.\n",
    "    :param save_fig: Wenn True, wird die Figur gespeichert.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Scaler laden\n",
    "    scaler = joblib.load('./scaler/target_scaler.pkl')\n",
    "    \n",
    "    # CSV-Datei laden\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    \n",
    "    # Wenn keine Modellnamen übergeben werden, alle Modelle aus der CSV verwenden\n",
    "    if model_names is None:\n",
    "        model_names = df['Model Name'].tolist()\n",
    "    elif isinstance(model_names, str):  # Falls nur ein einzelner Modellname übergeben wird\n",
    "        model_names = [model_names]\n",
    "\n",
    "    # Rückskalieren der echten Werte\n",
    "    y_data_rescaled = scaler.inverse_transform(y_data.reshape(-1, 1))\n",
    "\n",
    "    # Erstelle einen Plotly-Plot\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Füge die echten Werte hinzu (dicke schwarze Linie)\n",
    "    fig.add_trace(go.Scatter(x=dates, y=y_data_rescaled.flatten(), mode='lines', name=f'Echte {data_type} Werte', line=dict(color='black', width=3)))\n",
    "\n",
    "    # Farben für die Modelle festlegen\n",
    "    model_colors = pc.qualitative.Set1  # Eine Liste von Plotly-Farben (bis zu 9 verschiedene Farben)\n",
    "\n",
    "    # Vorhersagen der ausgewählten Modelle plotten\n",
    "    for idx, model_name in enumerate(model_names):\n",
    "        if model_name in df['Model Name'].values:\n",
    "            # Extrahiere den window_size und future_steps aus dem Modellnamen (z.B. 'model_20211010-101010_ws30_fs5_...')\n",
    "            window_size = int(model_name.split('_ws')[1].split('_')[0])\n",
    "            future_steps = int(model_name.split('_fs')[1].split('_')[0])  # Hier future_steps extrahieren\n",
    "\n",
    "            # Bereite die Daten für das Modell mit der extrahierten window_size vor\n",
    "            X_windowed = create_windowed_data_for_model(X_data, window_size)\n",
    "\n",
    "            # Lade das Modell\n",
    "            model = load_model(f'./models/{model_name}', compile=False)\n",
    "\n",
    "            # Vorhersagen machen\n",
    "            y_pred = model.predict(X_windowed)\n",
    "\n",
    "            # Reshape der y_pred Array für die Rückskalierung basierend auf future_steps\n",
    "            y_pred_reshaped = y_pred.reshape(-1, future_steps)\n",
    "\n",
    "            # Rückskalieren der Vorhersagen\n",
    "            y_pred_rescaled = scaler.inverse_transform(y_pred_reshaped)\n",
    "\n",
    "            # Plot der Vorhersagen (Punkte von tmax-future_steps bis tmax)\n",
    "            tmax = len(y_data_rescaled)  # Das Ende des Zeitraums\n",
    "            prediction_indices = range(tmax - future_steps, tmax)  # Indizes für die Vorhersagen\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[dates[i] for i in prediction_indices],  # Datumswerte für die Vorhersagepunkte\n",
    "                y=y_pred_rescaled[-1, :],  # Letztes Fenster verwenden\n",
    "                mode='markers',\n",
    "                name=f'{model_name} (Vorhersage)',\n",
    "                marker=dict(symbol='circle', size=8, color=model_colors[idx % len(model_colors)])  # Gleiche Farbe für Modell\n",
    "            ))\n",
    "\n",
    "            # Plot der Eingabedaten (Punkte von tmax-future_steps-windowsize bis tmax-future_steps)\n",
    "            input_indices = range(tmax - future_steps - window_size, tmax - future_steps)  # Indizes für die Eingabedaten\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[dates[i] for i in input_indices],  # Datumswerte für die Eingabedaten\n",
    "                y=y_data_rescaled[input_indices].flatten(),  # Eingabewerte\n",
    "                mode='markers',\n",
    "                name=f'{model_name} (Eingabe)',\n",
    "                marker=dict(symbol='x', size=8, color=model_colors[idx % len(model_colors)])  # Gleiche Farbe wie Vorhersage\n",
    "            ))\n",
    "\n",
    "        else:\n",
    "            print(f\"Modell {model_name} wurde in der CSV-Datei nicht gefunden.\")\n",
    "\n",
    "    # Layout des Plots\n",
    "    fig.update_layout(\n",
    "        title=f'Vorhersagen der Modelle auf {data_type}daten',\n",
    "        xaxis_title='Zeit',\n",
    "        yaxis_title='Preis',\n",
    "        showlegend=True\n",
    "    )\n",
    "\n",
    "    # Plot anzeigen\n",
    "    fig.show(renderer='browser')\n",
    "    \n",
    "    # Optionales Speichern des Plots\n",
    "    if save_fig:\n",
    "        fig.write_html(f\"./plots/{time.strftime('%Y%m%d-%H%M%S')}.html\")\n",
    "\n",
    "\n",
    "def create_windowed_data_for_model(X_data, window_size):\n",
    "    \"\"\"\n",
    "    Bereitet die Daten so vor, dass sie für Modelle mit unterschiedlicher window_size verwendet werden können.\n",
    "    :param X_data: Originale Daten, die vorfenstert werden sollen.\n",
    "    :param window_size: Die Fenstergröße, die für das Modell verwendet wurde.\n",
    "    :return: Fensterartige Daten für das Modell.\n",
    "    \"\"\"\n",
    "    X_windowed = []\n",
    "    for i in range(window_size, len(X_data)):\n",
    "        X_windowed.append(X_data[i - window_size:i])\n",
    "    return np.array(X_windowed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84b268fc-dca3-4d77-8b3c-d36726efcd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 1s 434us/step\n",
      "195/195 [==============================] - 1s 719us/step\n",
      "195/195 [==============================] - 0s 296us/step\n",
      "193/193 [==============================] - 1s 2ms/step\n",
      "195/195 [==============================] - 0s 472us/step\n",
      "195/195 [==============================] - 0s 538us/step\n",
      "195/195 [==============================] - 0s 583us/step\n",
      "195/195 [==============================] - 1s 997us/step\n",
      "193/193 [==============================] - 3s 12ms/step\n",
      "193/193 [==============================] - 1s 2ms/step\n",
      "195/195 [==============================] - 3s 549us/step\n",
      "195/195 [==============================] - 0s 290us/step\n",
      "195/195 [==============================] - 0s 367us/step\n",
      "195/195 [==============================] - 0s 785us/step\n",
      "193/193 [==============================] - 1s 2ms/step\n",
      "193/193 [==============================] - 1s 4ms/step\n",
      "195/195 [==============================] - 0s 411us/step\n",
      "194/194 [==============================] - 0s 597us/step\n",
      "195/195 [==============================] - 1s 2ms/step\n",
      "193/193 [==============================] - 1s 2ms/step\n",
      "195/195 [==============================] - 0s 425us/step\n",
      "195/195 [==============================] - 0s 1ms/step\n",
      "195/195 [==============================] - 0s 408us/step\n",
      "195/195 [==============================] - 1s 871us/step\n",
      "195/195 [==============================] - 1s 976us/step\n",
      "195/195 [==============================] - 0s 944us/step\n",
      "195/195 [==============================] - 0s 474us/step\n",
      "195/195 [==============================] - 0s 437us/step\n",
      "195/195 [==============================] - 0s 286us/step\n",
      "195/195 [==============================] - 0s 634us/step\n",
      "193/193 [==============================] - 1s 2ms/step\n",
      "195/195 [==============================] - 0s 341us/step\n",
      "195/195 [==============================] - 0s 461us/step\n",
      "195/195 [==============================] - 0s 438us/step\n",
      "195/195 [==============================] - 1s 2ms/step\n",
      "195/195 [==============================] - 0s 535us/step\n",
      "195/195 [==============================] - 0s 326us/step\n",
      "195/195 [==============================] - 0s 652us/step\n",
      "195/195 [==============================] - 0s 413us/step\n",
      "195/195 [==============================] - 0s 423us/step\n",
      "195/195 [==============================] - 0s 382us/step\n",
      "194/194 [==============================] - 2s 7ms/step\n",
      "193/193 [==============================] - 1s 2ms/step\n",
      "195/195 [==============================] - 1s 814us/step\n",
      "194/194 [==============================] - 2s 8ms/step\n",
      "195/195 [==============================] - 1s 837us/step\n",
      "195/195 [==============================] - 1s 685us/step\n",
      "194/194 [==============================] - 0s 1ms/step\n",
      "195/195 [==============================] - 0s 461us/step\n",
      "195/195 [==============================] - 0s 1ms/step\n",
      "193/193 [==============================] - 0s 1ms/step\n",
      "195/195 [==============================] - 0s 484us/step\n",
      "195/195 [==============================] - 1s 4ms/step\n",
      "193/193 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "plot_predictions_from_models(scaled_features, scaled_target, data_type='Prediction', csv_filename=csv_filename, dates=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e77d412-7462-4bab-a332-78bf3e04ff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_from_models(scaled_features, scaled_target, data_type='Prediction', model_names=['model_20241011-171432_ws1_bs5_epochs30_units64_layers1.keras'], csv_filename=csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3db64d-0447-429f-99e0-5577929e6854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
